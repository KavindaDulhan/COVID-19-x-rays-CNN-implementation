{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Acknowledgements\n\n- Dataset from https://github.com/ieee8023/covid-chestxray-dataset\n- COVID-19 Detector code from https://github.com/JordanMicahBennett/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# General libraries\nimport numpy as np\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Deep learning libraries\n#import keras.backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\n\n#Util Component 1: Confusion matrix report/Accuracy measures\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# disabling warnings\nimport logging\nlogging.getLogger('tensorflow').disabled = True #Jordan_note: Disable red warning lines seen at model architecture creation.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def renderConfusionMetrics ( ___model, _testData, _testLabels, enableTraining, ___train_gen, ___test_gen, __batch_size, __epochs, hdf5_testSaveFileName ):\n    preds = ___model.predict(_testData)\n\n    acc = accuracy_score(_testLabels, np.round(preds))*100\n    cm = confusion_matrix(_testLabels, np.round(preds))\n    tn, fp, fn, tp = cm.ravel()\n\n\n    print('\\nCONFUSION MATRIX FORMAT ------------------\\n')\n    print(\"[true positives    false positives]\")\n    print(\"[false negatives    true negatives]\\n\\n\")\n\n    print('CONFUSION MATRIX ------------------')\n    print(cm)\n\n    print('\\nTEST METRICS ----------------------')\n    precision = tp/(tp+fp)*100\n    recall = tp/(tp+fn)*100\n    specificity = tn/(tn+fp)*100 #Jordan_note: added specificity calculation \n    print('Accuracy: {}%'.format(acc))\n    print('Precision: {}%'.format(precision))\n    print('Recall/Sensitivity: {}%'.format(recall)) #Jordan_note: added sensitivity label\n    print('Specificity {}%'.format(specificity)) #Jordan_note: added specificity calculation \n    print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n\n\n    if enableTraining:\n        checkpoint = ModelCheckpoint(filepath=hdf5_testSaveFileName, save_best_only=True, save_weights_only=True)\n        lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n        early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n\n\n        hist = ___model.fit_generator(\n                   ___train_gen, steps_per_epoch=___test_gen.samples // __batch_size, \n                   epochs=__epochs, validation_data=___test_gen, \n                   validation_steps=___test_gen.samples // __batch_size, callbacks=[checkpoint, lr_reduce])\n\n        print('\\nTRAIN METRIC ----------------------')\n        print('Covid19 Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(hist.history[met])\n        ax[i].plot(hist.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['train', 'val'])\n    plt.savefig('train_val_acc_loss.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n\n    # Second component of main path (≈3 lines)\n    X = Conv2D(F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### (≈2 lines)\n    X_shortcut = Conv2D(F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n    \n    # Second component of main path (≈3 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNet50(_img_dims, classes = 1):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    input_shape = (_img_dims, _img_dims, 3)\n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    ### START CODE HERE ###\n\n    # Stage 3 (≈4 lines)\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4 (≈6 lines)\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5 (≈3 lines)\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n    X = AveragePooling2D(pool_size=(2, 2))(X)\n    \n    ### END CODE HERE ###\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    inputs = X_input\n    output = X\n    # Create model\n    #model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return inputs,output\n\ndef process_data(___inputPath, img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1./255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=___inputPath+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=___inputPath+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n        for img in (os.listdir(___inputPath + 'test' + cond)):\n            img = cv2.imread(___inputPath+'test'+cond+img,0) #Replace plt.imread, with  gray scale cv2.imread(path,0), so that ui's image load process doesn't throw a pyimage10 error\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') / 255\n            if cond=='/NORMAL/':\n                label = 0\n            elif cond=='/PNEUMONIA/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Util Component 2:model architecture description\ndef defineModelArchitecture (_img_dims ):\n    # Input layer\n    inputs = Input(shape=(_img_dims, _img_dims, 3))\n\n    # First conv block\n    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # Second conv block\n    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # Third conv block\n    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # Fourth conv block\n    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(rate=0.2)(x)\n\n    # Fifth conv block\n    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(rate=0.2)(x)\n\n    # FC layer\n    x = Flatten()(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(rate=0.7)(x)\n    x = Dense(units=128, activation='relu')(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(units=64, activation='relu')(x)\n    x = Dropout(rate=0.3)(x)\n\n    # Output layer\n    output = Dense(units=1, activation='sigmoid')(x)\n    \n    return inputs, output\n\n\n###########\n#Util Component 3: Data processor\n#Note: This process does not use validation path, because validation path in the original competion reasonably had too little data (8 samples) to create any insight.\n# the \"directoryProcessArray\" param from \"reportFileDistributions\" function corresponds to the hard-coded sub-directories of train and test, excluding val.\ndef process_data(___inputPath, img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1./255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=___inputPath+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=___inputPath+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n        for img in (os.listdir(___inputPath + 'test' + cond)):\n            img = cv2.imread(___inputPath+'test'+cond+img,0) #Replace plt.imread, with  gray scale cv2.imread(path,0), so that ui's image load process doesn't throw a pyimage10 error\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') / 255\n            if cond=='/NORMAL/':\n                label = 0\n            elif cond=='/PNEUMONIA/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels\n    \n\n###########\n#Util Component 4: Report file distributions\n#directoryProcessArray eg, = ['train', 'val', 'test'], in the case that training val and test folders exist in sub-dir for processing.\ndef reportFileDistributions (___inputPath, directoryProcessArray):\n    for _set in directoryProcessArray:\n        n_normal = len(os.listdir(___inputPath + _set + '/NORMAL'))\n        n_infect = len(os.listdir(___inputPath + _set + '/PNEUMONIA'))\n        print('Set: {}, normal images: {}, regular pneumonia images: {}'.format(_set, n_normal, n_infect))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reportFileDistributions (___inputPath, directoryProcessArray):\n    for _set in directoryProcessArray:\n        n_normal = len(os.listdir(___inputPath + _set + '/NORMAL'))\n        n_infect = len(os.listdir(___inputPath + _set + '/PNEUMONIA'))\n        print('Set: {}, normal images: {}, regular pneumonia images: {}'.format(_set, n_normal, n_infect))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting seeds for reproducibility\nseed = 232\nnp.random.seed(seed)\ntf.random.set_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nimg_dims = 150\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs, output = ResNet50(img_dims, classes = 1)\ninputs, output = defineModelArchitecture (_img_dims )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Non-COVID-19 Lung Pneumonia Detection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating model and compiling\nmodel_pneumoniaDetector = Model(inputs=inputs, outputs=output)\nmodel_pneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_pneumoniaDetector.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path_b = '../input/chest-xray-pneumonia/chest_xray/chest_xray/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Report file distributions\nreportFileDistributions (input_path_b, ['train', 'val', 'test'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the data\ntrain_gen, test_gen, test_data_b, test_labels_b = process_data(input_path_b, img_dims, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"renderConfusionMetrics(model_pneumoniaDetector, test_data_b, test_labels_b, True, train_gen, test_gen, batch_size, 10, 'model_weights.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Lung Pneumonia Detection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs, output = ResNet50(img_dims, classes = 1)\n\n# Creating model and compiling\nmodel_covid19PneumoniaDetector = Model(inputs=inputs, outputs=output)\nmodel_covid19PneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_covid19PneumoniaDetector.load_weights('model_weights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path_d = '../input/covid19-xray-dataset-train-test-sets/xray_dataset_covid19/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reportFileDistributions (input_path_d, ['train', 'test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen_d, test_gen_d, test_data_d, test_labels_d = process_data(input_path_d, img_dims, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"renderConfusionMetrics(model_covid19PneumoniaDetector, test_data_d, test_labels_d, True, train_gen_d, test_gen_d, batch_size, 10, 'covid19_model_weights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n#from resnets_utils import *\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n    \n    # Second component of main path (≈3 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    np.random.seed(1)\n    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n    X = np.random.randn(3, 4, 4, 6)\n    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n    test.run(tf.global_variables_initializer())\n    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n    print(\"out = \" + str(out[0][1][1][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n\n    # Second component of main path (≈3 lines)\n    X = Conv2D(F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### (≈2 lines)\n    X_shortcut = Conv2D(F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNet50(input_shape = (150, 150, 3), classes = 2):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [150, 150, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [150, 150, 256], stage=2, block='b')\n    X = identity_block(X, 3, [150, 150, 256], stage=2, block='c')\n\n    ### START CODE HERE ###\n\n    # Stage 3 (≈4 lines)\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4 (≈6 lines)\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5 (≈3 lines)\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n    X = AveragePooling2D(pool_size=(2, 2))(X)\n    \n    ### END CODE HERE ###\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet50(input_shape = (150, 150, 3), classes = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n\n[1] Joseph Paul Cohen and Paul Morrison and Lan Dao. COVID-19 image data collection, arXiv, 2020. https://github.com/ieee8023/covid-chestxray-dataset\n\n[2] https://github.com/JordanMicahBennett/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Thank you! I'll be updating this kernel from time to time, when new COVID-19 images come in. Stay safe and happy Kaggling everyone! :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}